

内存映射，简而言之就是将内核空间的一段内存区域映射到用户空间。映射成功后，用户对这段内存区域的修改可以直接反映到内核空间，相反，内核空间对这段区域的修改也直接反映用户空间。那么对于内核空间与用户空间两者之间需要大量数据传输等操作的话效率是非常高的。当然，也可以将内核空间的一段内存区域同时映射到多个进程，这样还可以实现进程间的共享内存通信。

系统调用mmap()就是用来实现上面说的内存映射。最长见的操作就是文件（在Linux下设备也被看做文件）的操作，可以将某文件映射至内存(进程空间)，如此可以把对文件的操作转为对内存的操作，以此避免更多的lseek()与read()、write()操作，这点对于大文件或者频繁访问的文件而言尤其受益。



![[Pasted image 20230217114451.png]]


通常使用mmap()的三种情况： **提高I/O效率、匿名内存映射、共享内存进程通信** 。


内存映射使用场景

-   X Window服务器
-   众多内存数据库如MongoDB操作数据,就是把文件磁盘内容映射到内存中进行处理,为什么会提高效率? 很多人不解. 下面就深入分析内存文件映射.
-   通过malloc来分配大内存其实调用的是mmap，可见在malloc(10)的时候调用的是brk, malloc(10 * 1024 * 1024)调用的是mmap;

操作系统提供的内存映射机制，对应的系统调用为mmap()/nunmap() 通过它可以将文件数据映射到内核地址空间，直接进行操作，在操作完成之后再刷回去。

整个时序图如下：
![[Pasted image 20230217144908.png]]


首先调用mmap() 系统函数，将硬件上的内容映射到进程上的虚拟内存中，那么该进程可以对这个虚拟内存进行操作，操作完成之后，将数据更新刷新。再次调用munmap() 进行调用。

但是上面的过程仍然需要发生4次上下文切换，另外，它需要在快表中（TLB）中始终维持着所有数据对应的地址空间，知道刷写完成，因此处理缺页的overhaul也会变得更大。






# 与常规文件操作对比




总结来说，常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。写操作也是一样，待写入的buffer在内核空间不能直接访问，必须要先拷贝至内核空间对应的主存，再写回磁盘中（延迟写回），也是需要两次数据拷贝。

而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。

总结：少了一次CPU拷贝。

**总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。** 

说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高。





