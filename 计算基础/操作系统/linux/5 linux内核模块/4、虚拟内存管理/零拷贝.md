
https://jaminzhang.github.io/os/IO-Model-06-Direct-IO/

# 0、背景

**内存**
内存又称主存，**是CPU能直接寻址的存储空间**，其作用是存放指令和数据，并能由中央处理器（CPU）直接随机存取。 

![[Pasted image 20230217100031.png]]

**内核缓冲区和用户缓冲区**

![[Pasted image 20230217112021.png]]


不同的就是，内核缓冲区处理的是内核空间和磁盘之间的数据传递，目的是减少访问磁盘的次数；而用户缓冲区处理的是用户空间和内核空间的数据传递，目的是减少系统调用的次数（感觉这句话总结的不错，给自己点个赞）


# 1、零拷贝

零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。实现零拷贝用到的最主要技术是 DMA 数据传输技术和内存区域映射技术。

-   零拷贝机制可以减少数据在内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。
-   零拷贝机制可以减少用户进程地址空间和内核地址空间之间因为上下文切换而带来的 CPU 开销。

# 2、物理内存和虚拟内存

物理内存（Physical memory）是相对于虚拟内存（Virtual Memory）而言的。物理内存指通过物理内存条而获得的内存空间，

虚拟内存是计算机系统内存管理的一种技术。 它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间）。而实际上，虚拟内存通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换，加载到物理内存中来。



通过上面的介绍，我们可以简单的将用户进程申请并访问物理内存（或磁盘存储空间）的过程总结如下：

1.  用户进程向操作系统发出内存申请请求
2.  系统会检查进程的虚拟地址空间是否被用完，如果有剩余，给进程分配虚拟地址
3.  系统为这块虚拟地址创建的内存映射（Memory Mapping），并将它放进该进程的页表（Page Table）
4.  系统返回虚拟地址给用户进程，用户进程开始访问该虚拟地址
5.  CPU 根据虚拟地址在此进程的页表（Page Table）中找到了相应的内存映射（Memory Mapping），但是这个内存映射（Memory Mapping）没有和物理内存关联，于是产生缺页中断
6.  操作系统收到缺页中断后，分配真正的物理内存并将它关联到页表相应的内存映射（Memory Mapping）。中断处理完成后 CPU 就可以访问内存了
7.  当然缺页中断不是每次都会发生，只有系统觉得有必要延迟分配内存的时候才用的着，也即很多时候在上面的第 3 步系统会分配真正的物理内存并和内存映射（Memory Mapping）进行关联。

# 3、内核空间和用户空间

操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。 在 Linux 系统中，内核模块运行在内核空间，对应的进程处于内核态；而用户程序运行在用户空间，对应的进程处于用户态。


内核进程和用户进程所占的虚拟内存比例是 1:3，而 Linux x86_32 系统的寻址空间（虚拟存储空间）为 4G（2的32次方），将最高的 1G 的字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF）供内核进程使用，称为内核空间；而较低的 3G 的字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个用户进程使用，称为用户空间。下图是一个进程的用户空间和内核空间的内存布局：

![[Pasted image 20230217113013.png]]


## 3.1 内核空间

内核空间总是驻留在内存中，它是为操作系统的内核保留的。应用程序是不允许直接在该区域进行读写或直接调用内核代码定义的函数的。上图左侧区域为内核进程对应的虚拟内存，按访问权限可以分为进程私有和进程共享两块区域。

-   进程私有的虚拟内存：每个进程都有单独的内核栈、页表、task 结构以及 mem_map 结构等。
-   进程共享的虚拟内存：属于所有进程共享的内存区域，包括物理存储器、内核数据和内核代码区域。


## 3.2 用户空间

每个普通的用户进程都有一个单独的用户空间，处于用户态的进程不能访问内核空间中的数据，也不能直接调用内核函数的 ，因此要进行系统调用的时候，就要将进程切换到内核态才行。用户空间包括以下几个内存区域：

-   运行时栈：由编译器自动释放，存放函数的参数值，局部变量和方法返回值等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈顶，调用结束后调用信息会被弹出弹出并释放掉内存。栈区是从高地址位向低地址位增长的，是一块连续的内在区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。
-   运行时堆：用于存放进程运行中被动态分配的内存段，位于 BSS 和栈中间的地址位。由卡发人员申请分配（malloc）和释放（free）。堆是从低地址位向高地址位增长，采用链式存储结构。频繁地 malloc/free 造成内存空间的不连续，产生大量碎片。当申请堆空间时，库函数按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。
-   代码段：存放 CPU 可以执行的机器指令，该部分内存只能读不能写。通常代码区是共享的，即其它执行程序可调用它。假如机器中有数个进程运行相同的一个程序，那么它们就可以使用同一个代码段。
-   未初始化的数据段：存放未初始化的全局变量，BSS 的数据在程序开始执行之前被初始化为 0 或 NULL。
-   已初始化的数据段：存放已初始化的全局变量，包括静态全局变量、静态局部变量以及常量。
-   内存映射区域：例如将动态库，共享内存等虚拟空间的内存映射到物理空间的内存，一般是 mmap 函数所分配的虚拟内存空间。

## 3.3 linux的内部层次结构

内核态可以执行任意命令，调用系统的一切资源，而用户态只能执行简单的运算，不能直接调用系统资源。用户态必须通过系统接口（System Call），才能向内核发出指令。比如，当用户进程启动一个 bash 时，它会通过 getpid() 对内核的 pid 服务发起系统调用，获取当前用户进程的 ID；当用户进程通过 cat 命令查看主机配置时，它会对内核的文件子系统发起系统调用。

![[Pasted image 20230217113408.png]]

-   内核空间可以访问所有的 CPU 指令和所有的内存空间、I/O 空间和硬件设备。
-   用户空间只能访问受限的资源，如果需要特殊权限，可以通过系统调用获取相应的资源。
-   用户空间允许页面中断，而内核空间则不允许。
-   内核空间和用户空间是针对线性地址空间的。
-   x86 CPU中用户空间是 0 - 3G 的地址范围，内核空间是 3G - 4G 的地址范围。x86_64 CPU 用户空间地址范围为0x0000000000000000 – 0x00007fffffffffff，内核地址空间为 0xffff880000000000 - 最大地址。
-   所有内核进程（线程）共用一个地址空间，而用户进程都有各自的地址空间。

有了用户空间和内核空间的划分后，Linux 内部层级结构可以分为三部分，从最底层到最上层依次是硬件、内核空间和用户空间，如下图所示:

![[Pasted image 20230217113440.png]]

## 3.4 内核缓冲区和用户缓存区

内核缓冲区和用户缓冲区都是用于数据传输的缓冲区，但它们的作用和特点不同：

1.  内核缓冲区：内核缓冲区是内核空间中的缓冲区，用于存储内核和用户之间传输的数据。内核缓冲区通常位于操作系统的页缓存中，是所有进程共享的。内核缓冲区可以被直接访问，无需进行内存映射，但访问需要进行系统调用，因此访问速度较慢。内核缓冲区可以使用DMA技术（直接内存访问）直接访问物理内存，提高数据传输的效率。
    
2.  用户缓冲区：用户缓冲区是用户空间中的缓冲区，用于存储应用程序和内核之间传输的数据。用户缓冲区通常位于应用程序的进程空间中，是进程私有的。用户缓冲区可以被直接访问，访问速度较快。但是，由于用户缓冲区是在用户空间中的，访问时需要进行内存映射，因此需要复制数据到内核缓冲区进行数据传输，这会导致数据的复制次数增多，影响数据传输的效率。
    

在零拷贝技术中，内核缓冲区用于在内核空间中存储数据，避免了将数据从内核缓冲区复制到用户空间缓冲区的过程，从而提高了数据传输的效率。通过使用DMA技术和sendfile()系统调用等技术，能够避免不必要的数据复制，实现零拷贝，提高数据传输的效率和系统的性能。

# 4、linux i/o 读写方式

linux提供了轮询、I/O 中断 以及DMA传输 这3种磁盘与主存之间的数据传输机制，其中轮询方式是基于死循环对I/O 端口进行不断检测，I/O 中断方式是指当数据到达时，磁盘主动向CPU发起的中断请求，由CPU自身负责数据的传输过程，DMA传输则在I/O中断的基础上引入了DMA磁盘控制器，由DMA磁盘控制器负责数据的传输，降低了I/O 中断对CPU资源的大量消耗。

## 4.1 I/O 中断原理

在DMA技术出现之前，应用程序与磁盘之间的I/O操作都是通过CPU的中断完成的，每次用户进程读取磁盘数据时，都需要CPU中断，然后发起 I/O 请求等待数据读取和拷贝完成，每次的I/O 切换都导致CPU的上下文切换。


![[Pasted image 20230216175602.png]]

1、用户进程向CPU发起reader() 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回
2、CPU在接受到指令以后对磁盘进行I/O 请求，将磁盘数据先放入到磁盘控制器缓冲区。
3、数据准备完成之后，磁盘向CPU发起I/O 中断
4、CPU 收到 I/O 中断以后将**磁盘缓冲区中的数据拷贝到内核缓冲区**，然后再**从内核缓冲区拷贝到用户缓冲区**
5、用户进程由内核态切换为用户态，接触阻塞状态，然后等待CPU的下一次执行时间钟



## 4.2 DMA传输原理

DMA的全称叫直接内存存取，是一种允许外围设备直接访问系统主内存（主存）的机制。也就是说。基于DMA访问方式，系统主内存（主存--内核缓冲区、用户进程缓存区所在的位置）与硬盘或网卡之间的数据传输可以绕开 CPU 的全程调度。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。

什么是主存：
内存又称主存，是CPU能直接寻址的存储空间，它的特点是存取速率快


![[Pasted image 20230216192104.png]]


有了 DMA 磁盘控制器接管数据读写请求以后，CPU 从繁重的 I/O 操作中解脱，数据读取操作的流程如下：

1.  用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回。
2.  CPU 在接收到指令以后对 DMA 磁盘控制器发起调度指令。
3.  DMA 磁盘控制器对磁盘发起 I/O 请求，将磁盘数据先放入磁盘控制器缓冲区，CPU 全程不参与此过程。
4.  数据读取完成后，DMA 磁盘控制器会接受到磁盘的通知，将数据从磁盘控制器缓冲区拷贝到内核缓冲区。
5.  DMA 磁盘控制器向 CPU 发出数据读完的信号，由 CPU 负责将数据从内核缓冲区拷贝到用户缓冲区。（内核缓冲区和用户缓冲区 也是在主存里面） 用户进程缓冲区
6.  用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟。

# 5. 传统I/O方式

传统的访问方式是通过 write() 和 read() 两个系统调用实现的，通过 read() 函数读取文件到到缓存区中，然后通过 write() 方法把缓存中的数据输出到网络端口，

![[Pasted image 20230216192602.png]]

整个数据的读写过程，涉及了2次CPU copy、2次DMA copy一共四次copy，以及4次上下文切换。

上下文切换：当用户程序向内核发起系统调用时，CPU将用户进程从用户态切换到内核态；当系统调用返回时候，cpu将用户进程从内核态切换为用户态，

cpu拷贝：由cpu直接处理数据的传输（将内核缓冲区的数据copy到用户缓冲区），此时会一直占用CPU资源。

DMA拷贝：由CPU箱DMA磁盘控制器发起指令，由DMA控制器来处理数据的传送（从磁盘缓冲copy到内核缓冲区），数据传送完毕之后再把信息反馈给CPU，从而减轻了CPU资源的占有率。

## 5.1. 传统读操作
  
当应用程序执行read系统调用读取一块数据的时候，如果这块数据已经存在于用户进程的页内存中，就直接从内核中读取数据，如果数据不存在，则现将数据从磁盘记载数据到内核空间的读缓存(read buffer中)，再从读缓存拷贝到用户进程的页内存中。

## 5.1. 传统写操作

当应用程序准备好数据，执行write系统调用发送网络数据时，先将数据从用户空间的页缓存拷贝到内核空间的网络缓冲区中，然后再将写缓冲中的数据拷贝到网卡设备上完成数据发送。

基于传统的 I/O 写入方式，write() 系统调用会触发 2 次上下文切换，1 次 CPU 拷贝和 1 次 DMA 拷贝，用户程序发送网络数据的流程如下：

1.  用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
2.  CPU 将用户缓冲区（user buffer）中的数据拷贝到内核空间（kernel space）的网络缓冲区（socket buffer）。
3.  CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。
4.  上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回。



# 6、零拷贝方式

在linux中零拷贝技术主要有三个思路：用户态直接I/O、减少数据copy次数以及写时复制。

-   用户态直接 I/O：应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。

-   减少数据拷贝次数：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。

-   写时复制技术：写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。

总结：零拷贝的主流实现思路：减少cpu的拷贝次数，

  
## 6.1用户态直接I/O

用户态直接 I/O 使得应用进程或运行在用户态（user space）下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在数据传输过程除了进行必要的虚拟存储配置工作之外，不参与任何其他工作，这种方式能够直接绕过内核，极大提高了性能。
用户缓存区直接访问磁盘

![[Pasted image 20230216194319.png]]

用户态直接I/O 只能使用于不需要内核缓冲区处理的应用程序，这样应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，比如数据库管理系统就是一个代表，其次，这种零拷贝机制会直接操作磁盘I/O，由于CPU和磁盘I/O之间的执行时间差距，会造成大量资源的浪费，解决方案是配合异步I/O使用。


### 数据库管理系统

https://jaminzhang.github.io/os/IO-Model-06-Direct-IO/

#### 为什么需要内核缓存

引入内核缓冲区的目的在于提高磁盘文件的访问性能， 因为当进程需要读取磁盘文件时，如果文件内容已经在内核缓冲区中，那么就不需要再次访问磁盘； 而当进程需要向文件中写入数据时，实际上只是写到内核缓冲区便告诉进程已经写成功，而真正写入磁盘是通过一定的策略进行延迟的。

然而，对于一些较复杂的应用，比如数据库服务器，它们为了充分提高性能，希望绕过内核缓冲区， 由自己在用户态空间实现并管理 I/O 缓冲区，包括**缓存机制和写延迟机制**（由于CPU和磁盘之间的执行时间差距）等，以支持独特的查询机制， 比如数据库可以根据更加合理的策略来提高查询缓存命中率。 另一方面，绕过内核缓冲区也可以减少系统内存的开销，因为内核缓冲区本身就在使用系统内存。


Liunx 提供了对这种需求的支持，即在 open() 系统调用中增加参数选项 O_DIRECT， 用它打开的文件便可以绕过内核缓冲区的直接访问，这样便有效避免了 CPU 和内存的多余时间开销。


在 MySQL 中，对于 Innodb 存储引擎，其自身可以进行数据和索引的缓存管理，所以它对于内核缓冲区的依赖不是那么重要。 MySQL 提供了一种实现直接 I/O 的方法，在 my.cnf 配置中，可以在分配 Innodb 数据空间文件的时候， 通过使用 raw 分区跳过内核缓冲区，实现直接 I/O，这在 MySQL 的官方手册上略有介绍，但是不多， 主要涉及 raw 分区的使用，这是一种特别的分区，它不能像其他分区格式（比如 ext2）一样通过 mount 来挂载使用， 而是需要使用 raw 设备管理程序来加载。为 Innodb 使用 raw 分区的配置如下所示：

`innodb_data_file_path = /dev/sda5:100Gnewraw`

假设 /dev/sda5 是 raw 分区，在分区大小后面增加 newraw 关键字，便可以将 raw 分区作为数据空间， 并由 Innodb 存储引擎直接访问。具体的操作还涉及其他一些步骤，这里就不具体罗列了。

另外，MySQL 还提供了 innodb_flush_method 配置选项，你可以将它设置为如下形式： `innodb_flush_method = O_DIRECT`

这样便可以通过另一种方式来实现直接 I/O。

## 6.2 mmap+write

一种零拷贝方式是使用mmap+write 替换原来的read+write 方式，减少1次CPU拷贝操作，mmap是linux提供的一种内存映射文件方法，即将一个进程的地址空间中的一段虚拟地址映射到磁盘文件地址上。
![[Pasted image 20230217114147.png]]


使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射，从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程，然而内核读缓冲区（read buffer）仍需将数据到内核写缓冲区（socket buffer），大致的流程如下图所示：

![[Pasted image 20230217100522.png]]
  


基于mmap+write 系统调用的零拷贝方式，整个拷贝过程会发生4次上下文切换、1次CPU拷贝和2次DMA 拷贝，用户程序读写数据的流程如下：

-   用户进程通过 mmap() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
-   将用户进程的内核空间的读缓冲区（read buffer）与用户空间的缓存区（user buffer）进行内存地址映射。
-   CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。
-   上下文从内核态（kernel space）切换回用户态（user space），mmap 系统调用执行返回。
-   用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
-   CPU将读缓冲区（read buffer）中的数据拷贝到的网络缓冲区（socket buffer）。
-   CPU利用DMA控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。
-   上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回。


mmap主要的用处是提高I/O 性能，特别是针对大文件，对于小文件，内存映射文件反而会导致碎片空间的浪费，因为内存映射总是要对齐页边界，最小单位是4KB，一个5KB的文件将会映射占用8KB 内存，也会造成3kb内存的浪费。

mmap 的拷贝虽然减少了 1 次拷贝，提升了效率，但也存在一些隐藏的问题。当 mmap 一个文件时，如果这个文件被另一个进程所截获，那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止，SIGBUS 默认会杀死进程并产生一个 coredump，服务器可能因此被终止。

## 6.3 sendfile

sendfile 系统调用在 Linux 内核版本 2.1 中被引入，目的是简化通过网络在两个通道之间进行的数据传输过程。sendfile 系统调用的引入，不仅减少了 CPU 拷贝的次数，还减少了上下文切换的次数，它的伪代码如下：

```
sendfile(socket_fd, file_fd, len);
```

通过sendfile系统调用，数据可以直接在内核空间内部进行I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝，与mmap内存映射方式不同，sendfile调用I/O 数据对用户空间是完全不可见的，这是一次完全意义上的数据传输过程。

sendfile：sendfile是一种在网络套接字和文件之间进行数据传输的零拷贝技术，它可以将文件数据直接发送到网络套接字，而无需将数据从内核缓冲区复制到用户缓冲区。sendfile技术可以显著降低网络传输数据的CPU利用率和内存带宽使用率，从而提高系统性能

![[Pasted image 20230217102759.png]]


基于 sendfile 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下：

1.  用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
2.  CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。
3.  CPU 将读缓冲区（read buffer）中的数据拷贝到的网络缓冲区（socket buffer）。
4.  CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。
5.  上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。

相比较于 mmap 内存映射的方式，sendfile 少了 2 次上下文切换，但是仍然有 1 次 CPU 拷贝操作。sendfile 存在的问题是用户程序不能对数据进行修改，而只是单纯地完成了一次数据传输过程。

sendfile 单纯是将磁盘的某个数据进行读取之后，然后立马发出去。该过程中，用户程序是不能对数据进行修改的。

比如：外部请求与kafka服务之间读取数据，那么需要从磁盘中读取数据，然后从网卡中发送出去。


## 6.4 sendfile+DMA gather copy

Linux 2.4 版本的内核对 sendfile 系统调用进行修改，为 DMA 拷贝引入了 gather 操作。它将内核空间（kernel space）的读缓冲区（read buffer）中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket buffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作。


在硬件的支持下，sendfile拷贝方式不在从内核缓冲区的数据拷贝到socket缓冲区，仅仅是拷贝缓冲区文件描述符和数据长度的拷贝。这样DMA引擎直接利用gather操作将页缓冲中数据打包发送到网络中即可，本身就是和虚拟内存映射的思路类似。

![[Pasted image 20230217103558.png]]

基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下：

1.  用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
2.  CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。
3.  CPU 把读缓冲区（read buffer）的文件描述符（file descriptor）和数据长度拷贝到网络缓冲区（socket buffer）。
4.  基于已拷贝的文件描述符（file descriptor）和数据长度，CPU 利用 DMA 控制器的 gather/scatter 操作直接批量地将数据从内核的读缓冲区（read buffer）拷贝到网卡进行数据传输。
5.  上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。

sendfile + DMA gather copy 拷贝方式同样存在用户程序不能对数据进行修改的问题，而且本身需要硬件的支持，它只适用于将数据从文件拷贝到 socket 套接字上的传输过程。

## 6.6 写时复制

在某些情况下，**内核缓冲区可能被多个进程所共享**，如果某个进程想要这个共享区进行 write 操作，由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制的引入就是 Linux 用来保护数据的。

写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中。这样做并不影响其他进程对这块数据的操作，每个进程要修改的时候才会进行拷贝，所以叫写时拷贝。这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。

## 6.7 缓冲区共享

缓冲区共享方式完全改写了传统的 I/O 操作，因为传统 I/O 接口都是基于数据拷贝进行的，要避免拷贝就得去掉原先的那套接口并重新改写，所以这种方法是比较全面的零拷贝技术，目前比较成熟的一个方案是在 Solaris 上实现的 fbuf（Fast Buffer，快速缓冲区）。

fbuf 的思想是每个进程都维护着一个缓冲区池，这个缓冲区池能被同时映射到用户空间（user space）和内核态（kernel space），内核和用户共享这个缓冲区池，这样就避免了一系列的拷贝操作。

  
# 7、linux零拷贝对比

无论是传统 I/O 拷贝方式还是引入零拷贝的方式，2 次 DMA Copy 是都少不了的，因为两次 DMA 都是依赖硬件完成的。下面从 CPU 拷贝次数、DMA 拷贝次数以及系统调用几个方面总结一下上述几种 I/O 拷贝方式的差别。

![[Pasted image 20230217104526.png]]


# 8、java NIO零拷贝实现

在java NIO中的通道(channel) 就相当于操作系统的内核空间（kernel space）的缓冲区，而缓冲区（Buffer）对应的相当于操作系统的用户空间中的用户缓冲区。



# 9 Netty零拷贝

Netty 中的零拷贝和上面提到的操作系统层面上的零拷贝不太一样, 我们所说的 Netty 零拷贝完全是基于（Java 层面）用户态的，它的更多的是偏向于数据操作优化这样的概念，具体表现在以下几个方面：

-   Netty 通过 DefaultFileRegion 类对 java.nio.channels.FileChannel 的 tranferTo() 方法进行包装，在文件传输时可以将文件缓冲区的数据直接发送到目的通道（Channel）
-   ByteBuf 可以通过 wrap 操作把字节数组、ByteBuf、ByteBuffer 包装成一个 ByteBuf 对象, 进而避免了拷贝操作
-   ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝
-   Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝

其中第 1 条属于操作系统层面的零拷贝操作，后面 3 条只能算用户层面的数据操作优化。

  

# 10 RockerMq 和kafka对比

RocketMQ 选择了 mmap + write （减少一次CPU拷贝）这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输；而 Kafka 采用的是 sendfile 这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。但是值得注意的一点是，Kafka 的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。

  
![[Pasted image 20230217105552.png]]



kafka的索引文件使用的是mmap的方式，数据文件使用的是sendfile方式